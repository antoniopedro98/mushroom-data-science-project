# -*- coding: utf-8 -*-
"""Projeto Final Ciência de Dados - Antonio Pedro - Occupancy Estimation Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IiwcYnozz90imD5EL_FDgPoo5ptXSZD3

# Engenharia de Software para Ciência de Dados - PUC-Rio

### Classificação Automática de Presença com dados ambientais não intrusivos
Antonio Pedro Santos Alves

## 1. Definição do Problema

O dataset usado neste projeto final da disciplina de Engenharia de Software para Ciência de Dados é o **Room Occupancy Estimation Data Set**, publicado como parte de uma tese de Mestrado de 2020 na área de Machine Learning e IoT na instiuição indiana, *The International Institute of Information Technology - Hyderabad*. 

O objetivo é estimar o número de pessoas em uma sala a partir de sensores ambientais não intrusivos, capazes de medir temperatura, som, luz e CO2. Em outras palavras, dado que uma série de valores coletados pelos sensores está disponível para diferentes momentos ao longo do dia, o objetivo é **classificar se o ambiente está com nenhuma, uma, duas ou três pessoas**.

Para isso, o dataset consiste de diferentes atributos que são relacionados aos valores coletados pelos diferentes sensores presentes em uma sala e uma variável de classificação múltipla (0, 1, 2 ou 3) que indica o total de pessoas na sala. As variáveis ​​preditoras incluem dados sobre a data e tempo da medição, temperatura em graus, luz, som e CO2. No total, **16 atributos** estão presentes para caracterizar **10129** instâncias, que foram geradas a partir de 4 dias de coleta ininterruptos em uma sala de 6 por 4.8 metros.

O dataset foi coletado da [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation)

### 1.1 Descrição dos Atributos
1. **Date** - Data da coleta no formato *YYYY/MM/DD*
2. **Time** - Tempo exato da coleta no formato *HH:MM:SS*
3. **S1_Temp** - Temperatura capturada em *celsius* pelo sensor de temperatura 1
4. **S2_Temp** - Temperatura capturada em *celsius* pelo sensor de temperatura 2
5. **S3_Temp** - Temperatura capturada em *celsius* pelo sensor de temperatura 3
6. **S4_Temp** - Temperatura capturada em *celsius* pelo sensor de temperatura 4
7. **S1_Light** - Luz capturada em *Lux* pelo sensor de luz 1
8. **S2_Light** - Luz capturada em *Lux* pelo sensor de luz 2
9. **S3_Light** - Luz capturada em *Lux* pelo sensor de luz 3
10. **S4_Light** - Luz capturada em *Lux* pelo sensor de luz 4
11. **S1_Sound** - Som capturado em *volts* pelo sensor de som 1
12. **S2_Sound** - Som capturado em *volts* pelo sensor de som 2
13. **S3_Sound** - Som capturado em *volts* pelo sensor de som 3
14. **S4_Sound** - Som capturado em *volts* pelo sensor de som 4
15. **S5_CO2** - CO2 capturado em *PPM* pelo sensor de CO2
16. **S5_CO2_Slope** - CO2 capturado em *PPM* em uma janela deslizante de tempo pelo sensor de CO2
17. **S6_PIR** - Detecção de movimento *binário* (i.e, se houve movimento, o sensor guarda 1, caso contrário, 0) pelo sensor de movimento 1.
18. **S7_PIR** - Detecção de movimento *binário* (i.e, se houve movimento, o sensor guarda 1, caso contrário, 0) pelo sensor de movimento 2.
19. **Room_Occupancy_Count** - Total de pessoas na sala

### 1.2 User Stories

Como explicado em sala, a descrição e detalhamento de *user stories* ajuda na especificação e desenvolvimento de sistemas de Machine Learning. Assim, para este trabalho, podemos especificar a seguinte *user storie*

**[US01]** **Como** desenvolvedor de aplicações IoT **quero** identificar presença de pessoas em uma sala com sensores não intrusivos **para** melhorar a performance de sistemas automatizados de aquecimento e iluminação de ambiente

**[US01]** pode ser detalhada em termos do objetivo de Machine Learning (*ML Objective*), experiência do usuário (*User Experience*), infraestrutura (*Infrastructure*), modelo (*Model*) e dados (*Data*)

*   **ML Objective**
  *   **ML Problem and Context**: Problema de **Classificação Automática**
  *   **Organizational Goals**: Com a classificação automática de pessoas em um ambiente, esperamos **reduzir a conta de luz** em até **40%** dentro de **um mês** realizando o ajuste automático de temperatura e iluminação do ambiente.
  *   **User Goals**: Melhorar o consumo energético dos eletrodomésticos de aquecimento e iluminação
  *   **Model Goal**: O classificador deve fornecer uma **Acurácia > 90%, Precisão...**
  *   **ML Functionality**: Classificar um ambiente a partir de um conjunto de valores capturados por sensores em: **Sala Vazia**, **Sala com 1 pessoa**, **Sala com 2 pessoas** ou **Sala com 3 pessoas**
  *   **Leading Indicators**: O sucesso futuro do modelo deverá ser analisado a partir da fatura de energia do próximo mês corrente.
  *   **Customer Expectation**: Para cada **10 classificações**, o classificador deve errar somente **1 classificação**.
*   **User Experience**
  *   **Accountability**: O **responsável** pelas ações tomadas no classificador é o **Engenheiro de Machine Learning** responsável pelo desenvolvimento e implantação dos modelos.
  *   **Cost**: Cada **classificação correta** implica em um ajuste correto nos eletrodomésticos automatizados, ou seja, uma economia de no mínimo **R$ 10 por classificação**. Em caso de classificação errada, **não há economia** na fatura de energia.
  *   **Forcefulness**: Para toda classificação de ausência no ambiente, o sistema desliga o aquecimento e a iluminação. Para classificações de presença no ambiente, o sistema ajusta os eletrodomésticos de acordo com o número de pessoas.
  *   **Frequency**: O sistema interage **continuamente** com os eletrodomésticos presente no ambiente.
  *   **Interactiveness**: Toda classificação realizada é incorporada ao modelo após 1 mês. Em outras palavras, se uma classificação é realizada em Julho, este resultado é armezanado em um histórico que deverá ser incorporado à base de dados para treino e teste no novo modelo treinado e que estará pronto para uso em Agosto. Nos casos de classificação negativa, a classificação deve ser corrigida manualmente.
  *   **Value**: Aumento de confiança em sistemas inteligentes para gerenciamento de eletrodomésticos.
  *   **Visualization**: Os resultados do sistema devem ser apresentados mensalmente em um arquivo PDF que mostra um gráfico de linha comparativo entre o valor da conta de energia com o uso do classificador regulando os eletrodomésticos e com o uso dos mesmos de maneira parcial (12 horas ligados e 12 horas desligados)
*   **Infrastructure**
  *   **Data Streaming**: Os dados para classificação são fornecidos em tempo real através de sensores com um *delay* de 30ms
  *   **Execution Engine**: O classificador pode ser acessado por meio de
um *endpoint* especificado na API que está
hospedada em
https://aws.amazon.com/presence-classifier.
  *   **Incremental Learning**:  O modelo deve aprender com novos dados para toda classificação realizada e que tenha uma validação sobre a corretude da mesma (fato que ocorre mensalmente por classificação).
  *   **Integration**: O classificador deve interagir somente com o sistema de **aquecimento** e **iluminação** do ambiente
  *   **Safety**: O sistema deve realizar seus ajustes somente mediante a senha do **Responsável da Sala**. A inserção de
novos dados, por sua vez, só é realizada após a validação das classificações armazenadas no histórico e autorizadas mediante a senha do **Engenheiro de Machine Learning**.
  *   **Security**: A comunicação dos sensores com o sistema é realizada usando o protocolo **HTTPS**.
  *   **Storage**: O classificador estará disponível na infraestrutura *web service* da AWS e acessado via endpoint. Os dados usados na classificação estão armazenados em um **banco de dados não relacional** também armazenado na AWS.

  *   **Telemetry**: Nenhum dado além dos coletados pelos sensores e da senha do **Responsável da Sala** são necessários.
*   **Model**
  *   **Algorithm**: **Regressão Logística**, **SVM**, **Naive Bayes**,**KNN**, **AdaBoost**, **Gradient Boosting**, **Random Forests** e **Extra Trees**.
  *   **Explainability**: Toda classificação deve trazer consigo a **acurácia do classificador** e um **resumo dos valores coletados para aquela classificação**.
  *   **Inference Time**: A execução e classificação de uma nova instância deve ocorrer dentro de no máximo 2 segundos.
  *   **Input/Output**: As entradas para o classificador são **Date**, **Time**, **S1_Temp**, **S2_Temp**, **S3_Temp**,**S4_Temp**, **S1_Light**, **S2_Light**,**S3_Light**, **S4_Light**, **S1_Sound**,**S2_Sound**, **S3_Sound**, **S4_Sound**,**S5_CO2**, **S5_CO2_Slope**, **S6_PIR** e **S7_PIR**. A saída deve ser um rótulo **Sala Vazia**, **Sala com 1 pessoa**, **Sala com 2 pessoas** ou **Sala com 3 pessoas**
  *   **Learning Time**: O treino do modelo deve ocorrer em no máximo **5 horas**
  *   **Maintainability**: O modelo deve passar por uma **revisão mensal** e junto a isso, tem a **entrada de novas instâncias rotuladas**
  *   **ML Problem Type**: **Classificação** 
  *   **Model Performance**: O modelo deve ser avaliado sob a perspectiva de **Acurácia**, **Precisão**, **Recall**, **F1-Score**.
  *   **Model Size**: O modelo deve ter no máximo **10GB de dados** a serem manipulados.
  *   **Reproducibility**: É necessário ser possível replicar a criação do modelo utilizado e realizar experimentos sobre ele.
*   **Data**
  *   **Accuracy**: Dados devem ser coesos e relativos ao que os sensores capturaram em ambientes de produção. Dados de teste/fictícios não devem ser aplicados ao sistema de produção em hipótese alguma.
  *   **Baseline**: Um input com **10.129** instâncias validadas e rotuladas em um experimento de 4 dias em ambiente controlado.
  *   **Bias**: A base de dados possuir instâncias de todas as 4 situações (desde ninguém a 3 pessoas no ambiente).
  *   **Completeness**: A base de dados deve ser equilibrada em termos do total de instâncias referentes a cada uma das 4 situações (desde ninguém a 3 pessoas no ambiente, podendo haver no máximo uma diferença de 5% entre o total de instâncias nas classes.
  *   **Consistency**: Todas as instâncias devem possuir valores não nulos para todos os atributos. 
  *   **Credibility**: Dados devem refletir cenários e situações observados em contextos reais.
  *   **Data Operations**: Todos as instâncias usadas pelo modelo devem
ser rotuladas, bem como os resultados da
classificação.
  *   **Distribution**: A base de dados é dividida segundo uma validação de *train-test-split*, onde 70% da base é usado no treinamento, e 30% no teste.
  *   **Ethics & Privacy**: Os dados coletados não ferem a privacidade ou ética de nenhuma das pessoas presentes no ambiente.
  *   **Quantity**: O número **mínimo** de instâncias é de **10.129**.
  *   **Real usage**: Dados mais próximos ao ambiente externo em que o sistema será inserido devem ser fornecidos, de modo a aproximar o modelo da realidade em que ele será submetido.
  *   **Source**: Os dados de entrada serão provenientes de todos os sensores presentes no ambiente. Como conjunto inicial, o dataset presente neste [link](https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation) deverá ser utilizado.
  *   **Timeliness**: O tempo entre quando os dados são esperados quando estão disponíveis para uso deve ser de **5 segundos**.

## 2. Carga de Dados
"""

# Imports
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as ms
from matplotlib import cm
from pandas import set_option
from pandas.plotting import scatter_matrix
from sklearn.preprocessing import StandardScaler 
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier

# configuração para não exibir os warnings
import warnings
warnings.filterwarnings("ignore")

# Carrega arquivo csv usando Pandas através de uma URL

# URL do dataset
url = "https://raw.githubusercontent.com/antoniopedro98/occupancy-estimation-data-science-project/main/occupancy-estimation-dataset.csv"

# Lê o arquivo utilizando - primeira linha contém o cabeçalho neste caso
dataset = pd.read_csv(url, delimiter=',')

# breve visualização do dataset
dataset.head(10)

# breve visualização do dataset - final do mesmo
dataset.tail(10)

"""## 3. Estatísticas Descritivas"""

# Dimensões do dataset
dataset.shape

# Informações do dataset
dataset.info()

"""Pela célula anterior, foi possível observar que não há valores faltantes para nenhum dos atributos. Contudo, os dois primeiros atributos (de data e tempo) são identificados como *object*, sendo que se referem a períodos de tempo, somente. No momento, ambos não agregam às classificações a serem realizadas, portanto, nas análises descritivas e etapas posteriores, ambos serão desconsiderados."""

# Faz um resumo estatístico do dataset (média, desvio padrão, mínimo, máximo e os quartis) de todos os atributos, menos dos dois primeiros
dataset.describe()

# distribuição das classes
print(dataset.groupby('Room_Occupancy_Count').size())

"""Pela célula anterior, verificamos que o dataset tem as classes desbalanceadas. A ocorrência de ausência de pessoas no ambiente é muito maior que a união de todas as demais classes (com presença de pessoas no ambiente). Isso será tratado nas próximas células.

## 4. Visulizações

### 4.1. Unimodais
"""

# Histograma
dataset.hist(figsize = (22,12))
plt.show()

# Density Plot
dataset.plot(kind = 'density', subplots = True, layout = (6,3), sharex = False, figsize = (22,12))
plt.show()

# Boxplot
dataset.plot(kind = 'box', subplots = True, layout = (6,3), sharex = False, sharey = False, figsize = (22,12))
plt.show()

# Boxplot sem Outliers
dataset.plot(kind = 'box', subplots = True, layout = (6,3), sharex = False, sharey = False, figsize = (22,12), showfliers=False)
plt.show()

"""### 4.2. Multimodais


"""

# Matriz de Correlação com Matplotlib Seaborn
sns.set(rc={'figure.figsize':(22,12)})
sns.heatmap(dataset.corr(), annot=True, cmap='RdBu')

"""O resultado Heatmap mostra que os atributos são pouco correlacionados, com excecção dos que se tratam do mesmo sensor, como os sensores de temperatura e luz, que entre eles possuem uma correlação alta, até por se tratarem de sensores capturando dados parecidos. 

Por sua vez, o gráfico de dispersão (scatter plot) mostra o relacionamento entre duas variáveis. Vamos exibir um para cada par de atributos dos dataset, usando o Seaborn.
"""

# Scatter Plot com Seaborn
sns.pairplot(dataset, hue = "Room_Occupancy_Count", height = 2.5)

"""## 4. Conjunto de Treino e Teste

Para avaliar a performance de estratégias de classificação para o dataset em estudo, vamos realizar a divisão de 70/30. Isto é, usaremos 70% do conjunto de dados para treino e 30% para teste. 

Todos os atributos serão utilizados, exceto os aributos *Date* e *Time*, dado que eles não acrescentam em nada. Na descrição do dataset, os autores afirmam que o ambiente de geração dos dados era controlado e pouco influenciado pelas variações do dia (manhã ou noite). Logo, a remoção destes atributos não prejudicará este experimento, já que os que realmente são interessantes de se analisar são os relacionados aos sensores.
"""

class PreProcessor:
    # valor a ser utilizado para reprodução dos experimentos
    seed = 10
    # usaremos 30% de teste
    test_size = 0.30

    def preprocess(self, dataset_array: np.ndarray):
        """ 
          Divide o dataset em treino e teste
        """
        # exclui os atributos Date e Time
        X = dataset_array[:,2:18].astype('float')
        # a classe a ser predita é o último campo, que é Room_Occupancy_Count
        Y = dataset_array[:,18].astype('int')
        
        return train_test_split(X, Y, test_size=self.test_size, random_state=self.seed)

# cria um objeto PreProcessor()
preprocessor = PreProcessor()

# Separação em conjuntos de treino e teste
array = dataset.values

X_train, X_test, Y_train, Y_test = preprocessor.preprocess(array)

"""## 5. Modelos de Classificação

### 5.1. Criação e avaliação de modelos: linha base

Para decidir quais modelos terão melhor performance neste dataset, vale utilizar da técnica de validação cruzada (vista em aula) com 10 *folds* e avaliando os modelos usando a métrica de acurácia. 

A escolha da acurácia é uma boa alternativa dado que avalia a corretude das classificações. Logo ela sera a metrica de avaliação dos modelos. Uma alternativa poderia ser a métrica *balanced_accuracy*, que é ideal para datasets com classes desbalanceadas, porém, nas próximas etapas iremos tratar esse problema de outra forma.

Em seguida, vamos criar uma linha base de desempenho para esse problema, verificando vários modelos diferentes com suas configurações padrão. Utilizaremos os modelos de **regressão logística**, **máquinas de vetores de suporte** (SVM), **Naive Bayes** (NB) e **K-vizinhos mais próximos** (KNN). Além disso, também faremos uso dos métodos de ensemble, avaliando quatro modelos diferentes, sendo dois métodos de Boosting e dois de Bagging, são eles **AdaBoost** (AB), **Gradient Boosting** (GBM), **Random Forests** (RF) e **Extra Trees** (ET).

Para cada modelo, vamos executar o 10-fold cross-validation e os avaliaremos em termos de sua média e desvio padrão.
"""

class MLModel:
    # total de folds para o k-fold
    num_folds = 10
    # métrica de avaliação
    scoring = 'accuracy'
    # todos os modelos que serão utilizados
    models= [('Linear Regression', LogisticRegression(solver='liblinear')),
                 ('KNN', KNeighborsClassifier()),
                 ('Naive Bayes', GaussianNB()),
                 ('SVM', SVC(gamma='auto')),
                 ('AB', AdaBoostClassifier()),
                 ('GBM', GradientBoostingClassifier()),
                 ('RF', RandomForestClassifier(n_estimators=10)),
                 ('ET', ExtraTreesClassifier(n_estimators=10))]
    scaled_models = [('ScaledLogisticRegression', Pipeline([('Scaler', StandardScaler()) ,('LR', LogisticRegression(solver='liblinear'))])), 
                         ('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])),
                         ('ScaledNaiveBayes', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])),
                         ('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC(gamma='auto'))])),
                         ('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostClassifier())])),
                         ('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingClassifier())])),
                         ('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestClassifier(n_estimators=10))])),
                         ('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesClassifier(n_estimators=10))]))]
    minmax_models = [('ScaledMinMaxLogisticRegression', Pipeline([('Scaler', MinMaxScaler()) ,('LR', LogisticRegression(solver='liblinear'))])), 
                         ('ScaledMinMaxKNN', Pipeline([('Scaler', MinMaxScaler()),('KNN', KNeighborsClassifier())])),
                         ('ScaledMinMaxNaiveBayes', Pipeline([('Scaler', MinMaxScaler()),('NB', GaussianNB())])),
                         ('ScaledMinMaxSVM', Pipeline([('Scaler', MinMaxScaler()),('SVM', SVC(gamma='auto'))])),
                         ('ScaledMinMaxAB', Pipeline([('Scaler', MinMaxScaler()),('AB', AdaBoostClassifier())])),
                         ('ScaledMinMaxGBM', Pipeline([('Scaler', MinMaxScaler()),('GBM', GradientBoostingClassifier())])),
                         ('ScaledMinMaxRF', Pipeline([('Scaler', MinMaxScaler()),('RF', RandomForestClassifier(n_estimators=10))])),
                         ('ScaledMinMaxET', Pipeline([('Scaler', MinMaxScaler()),('ET', ExtraTreesClassifier(n_estimators=10))]))]


    def cross_validation(self, seed, X_train, Y_train, title, standardize=False, standardize_type=''):
        """ 
          Realiza o cross validation de todos os modelos salvos
        """
        np.random.seed(seed) # definindo uma semente global

        # resultado da classificação
        results = []
        # nomes dos modelos
        names = []
        # seleciona os modelos padronizados ou normais
        models = self.scaled_models if standardize else self.models
        if standardize_type and standardize:
          models = self.minmax_models if type == 'minmax' else self.scaled_models

        for name, model in models:
            kfold = KFold(n_splits=self.num_folds)
            # error_score='raise' ajuda a debugar caso algo dê errado na validação cruzada
            cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=self.scoring, error_score="raise")
            # guarda o resultado e o nome para a geração do gráfico
            results.append(cv_results)
            names.append(name)
            print(name + ":" + str(cv_results.mean()) + "(" + str(cv_results.std()) + ")")

        self.plot_boxplot(title, results, names)


    def plot_boxplot(self, title, results, names):
        # Comparação dos modelos em boxplots
        fig = plt.figure() 
        fig.suptitle(title) 
        ax = fig.add_subplot(111) 
        plt.boxplot(results) 
        ax.set_xticklabels(names) 
        plt.show()


    def optimize_grid_search(self, seed, model, param_grid, X_train, Y_train):
        np.random.seed(seed) # definindo uma semente global

        # Tuning do algoritmo desejado

        kfold = KFold(n_splits=self.num_folds)

        pipeline = Pipeline(steps=[('Scaler', StandardScaler()), model])

        grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring=self.scoring, cv=kfold)

        grid.fit(X_train, Y_train)

        print("Melhor Acurácia:" + str(grid.best_score_) + "| Configuração: " + str(grid.best_params_))

        means = grid.cv_results_['mean_test_score']
        stds = grid.cv_results_['std_test_score']
        params = grid.cv_results_['params']
        for mean, stdev, param in zip(means, stds, params):
            print("%f (%f): %r" % (mean, stdev, param))

# incializa o objeto com modelos
mlmodel = MLModel()
# realiza a validação cruzada
mlmodel.cross_validation(preprocessor.seed, X_train, Y_train, 'Comparação entre Modelos de Classificação')

"""Os resultados de média e desvio padrão (que caracterizam a acurácia média dos modelos), além da análise gráfica dos boxplots (que caracterizam a distribuição dos resultados), sugerem que o KNN, GradientBoosting, RandomForest e ExtraTrees têm muito potencial de serem bons classificadores para o nosso problema. 

Todavia, a distribuição desbalanceada dos atributos esteja afetando a acurácia dos algoritmos. Para isso, realizaremos esta mesma etapa com a padronização do dataset.

Vale destacar que em tese, nenhuma padronização de dados precisaria ser usada nos ensemble, dado que são modelos menos sensíveis às distribuições de dados. Mesmo assim, todos serão submetidos a esta padronização.

### 5.2. Criação e avaliação de modelos: dados padronizados

Como observado na etapa de Análise Descritiva, as classes presentes no dataset estão desbalanceadas e isso pode afetar a performance de modelos. Desta forma, vamos utilizar uma cópia padronizada do dataset de modo que cada atributo tenha média 0 e um desvio padrão 1. 

Para evitar o "vazamento de dados" na transformação, vale utilizar os pipelines (como visto em aula), que padronizam os dados e constroem o modelo para cada fold de teste de validação cruzada. Portanto, podemos obter uma estimativa justa de como cada modelo com dados padronizados funcionaria com dados não vistos.
"""

# realiza a validação cruzada com os modelos padronizados
mlmodel.cross_validation(preprocessor.seed, X_train, Y_train, 'Comparação entre Modelos de Classificação Padronizados', standardize=True)

"""Os resultados de média, desvio padrão e distribuição dos resultados nos boxplots, mostram uma melhora significativa de performance para o SVM e Linear Regression com os dados normalizados. A performance do KNN, GradientBoosting, RandomForest e ExtraTrees continuaram com boas performances, e o ganho com os dados normalizados foi baixo.

Uma alternativa seria utilizar o MinMaxScaler, em vez do StandardScaler, contudo o ganho foi pouco significativo, como mostra as próximas duas células
"""

# realiza a validação cruzada com os modelos padronizados usando o minmax
mlmodel.cross_validation(preprocessor.seed, X_train, Y_train, 'Comparação entre Modelos de Classificação Padronizados - MinMax', standardize=True, standardize_type='minmax')

"""Em resumo, os dados padronizados nos mostraram que a **Regressão Linar**, **KNN**, **SVM**, **GradientBoosting**, **RandomForest** e **ExtraTrees**  possuem boas performances na classificação do dataset. Todavia, todos têm uma série de customizações de hiperparâmetros, logo, a exploração dessas possiblidades podem ajudar na escolha de somente um deles.

### 5.3. Ajuste dos Modelos

Dado que todos os três algoritmos tiveram melhora de resultado com os dados normalizados, temos que os ajustes a serem explorados para cada um, assumirão que os dados estarão padronizados com *pipelines* e o *StandardScaler*.

#### Ajuste do KNN

Dois hiperparâmetros que afetam diretamente a performance do KNN são o número de vizinhos e as métricas de distância. Para tal, tentaremos todos os valores ímpares de k entre 1 a 51 e as métricas de distância *euclidiana*, *manhattan* e *minkowski*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'knn__n_neighbors': [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51],
    'knn__metric': ["euclidean", "manhattan", "minkowski"],
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('knn', KNeighborsClassifier()), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza distância de manhattan e k = 3, com acurácia de 0.9956276445698166.

#### Ajuste do Linear Regression

Dois hiperparâmetros também afetam diretamente a performance do Linear Regression são a força de regularização inversa (o C, o quanto flexibilizar a margem), a norma da penalidade. Para tal, tentaremos a variação de 0.1 a 2 (quanto menor, maior a regularização) e as penalidades *l1* e *l2*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'lr__C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0],
    'lr__penalty': ["l1", "l2"],
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('lr', LogisticRegression(solver='liblinear')), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza penalidade L1 e C = 2, com acurácia de 0.9923836389280677.

#### Ajuste do SVM
Iremos ajustar dois dos principais hiperparâmetros do algoritmo SVM: o valor de C (o quanto flexibilizar a margem) e o tipo de kernel utilizado.Para tal, tentaremos a variação de 0.1 a 2 (quanto menor, maior a regularização) e as funções *linear*, *poly*, *rbf* e *sigmoid*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'svc__C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0],
    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid']
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('svc', SVC(gamma='auto')), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza função kernel Linear e C = 0.3, com acurácia de 0.9954866008462624.

#### Ajuste do GradientBoosting
Iremos ajustar dois hiperparâmetros do ensemble GradientBoosting: o *criterion* e o *n_estimators*. Basicamente, eles medem, respectivamente, a qualidade da divisão realizada e o número de estágios de *boosting* a serem consideradas. Vamos variar o *criterion* para *friedman_mse*, *squared_error* e *mse*, e o *n_estimators* como *10*, *100*, *150* e *200*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'GBM__criterion': ['friedman_mse', 'squared_error', 'mse'],
    'GBM__n_estimators': [10, 100, 150, 200]
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('GBM', GradientBoostingClassifier()), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza criterion friedman_mse e n_estimators = 200, com acurácia de 0.997602256699577.

#### Ajuste do RandomForest
Iremos ajustar dois hiperparâmetros do ensemble RandomForest: o *criterion* e o *n_estimators*. Basicamente, eles medem, respectivamente, a qualidade da divisão realizada e o número de florestas a serem consideradas. Vamos variar o *criterion* para *gini*, *entropy* e *log_loss*, e o *n_estimators* como *10*, *100*, *150* e *200*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'RF__criterion': ['gini', 'entropy', 'log_loss'],
    'RF__n_estimators': [10, 100, 150, 200]
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('RF', RandomForestClassifier()), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza criterion entropy e n_estimators = 150, com acurácia de 0.9980253878702398.

#### Ajuste do ExtraTrees
Iremos ajustar dois hiperparâmetros do ensemble ExtraTrees: o *criterion* e o *n_estimators*. Basicamente, eles medem, respectivamente, a qualidade da divisão realizada e o número de florestas a serem consideradas. Vamos variar o *criterion* para *gini*, *entropy* e *log_loss*, e o *n_estimators* como *50*, *100*, *150* e *200*.
"""

# parâmetros de otimização do modelo
param_grid = {
    'ET__criterion': ['gini', 'entropy', 'log_loss'],
    'ET__n_estimators': [10, 100, 150, 200]
}
# otimiza o modelo para achar a melhor configuração
mlmodel.optimize_grid_search(preprocessor.seed, ('ET', ExtraTreesClassifier()), param_grid, X_train, Y_train)

"""Os resultados mostram que a melhor configuração encontrada utiliza criterion gini e n_estimators = 200, com acurácia de 0.9987306064880114. No caso, a **melhor configuração no conjunto de treino**.

## 6. Finalização do Modelo

Até aqui, verificamos que o ensemble ExtraTree com *criterion* gini e *n_estimators* = 200 foi o modelo que mostrou melhor acurácia para o problema no conjunto de treino. Logo, para finalizarmos este modelo, treinaremos em todo o conjunto de dados de treinamento (sem validação cruzada) e faremos predições para o conjunto de dados de teste que foi separado logo no início do exemplo, a fim de confirmarmos nossas descobertas.

Primeiro, iremos realizar a padronização dos dados de entrada. Depois, exibiremos a acurácia e a matriz de confusão:
"""

# Preparação do modelo
scaler = StandardScaler().fit(X_train)
rescaledX = scaler.transform(X_train)
model = ExtraTreesClassifier(criterion='gini', n_estimators=200)
model.fit(rescaledX, Y_train)

# Estimativa da acurácia no conjunto de teste
rescaledTestX = scaler.transform(X_test)
predictions = model.predict(rescaledTestX)
print(accuracy_score(Y_test, predictions))
print(confusion_matrix(Y_test, predictions))
print(classification_report(Y_test, predictions))

"""Por meio do conjunto de teste, verificamos que alcançamos uma acurácia próxima a 100% em dados não vistos. Valores semelhantes são esperados quando este modelo estiver executando em produção e fazendo predições para novos dados."""